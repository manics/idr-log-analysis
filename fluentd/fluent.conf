# Note use https://fluentular.herokuapp.com/ for testing regex's!

# idr.openmicroscopy.org Nginx
# Log format: main_timed_cache_upstream
# https://github.com/openmicroscopy/ansible-role-nginx-proxy/blob/1.6.0/templates/nginx-conf.j2#L39
<source>
  @type tail
  path /idr-nginx-logs/access.log*
  pos_file /fluentd/pos/idr-nginx-logs-access.pos
  read_from_head true
  tag nginx.access

  format /^(?<host>[^ ]*) - (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<request>(?<method>\S+) +(?<path1>/[^ \/\?]*)(?<path2>/[^ \/\?]*)?(?<path3>/[^ \/\?]*)?(?<path4>/[^ \/\?]*)?(?<path_n>/[^ \?]*)?(?<query>\?[^ ]*)? +(?<http_ver>\S*))?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")? "(?<forwarded>[^\"]*)" (?<reqtime>[^ ]*) (?<cachestatus>[^ ]*) (?<upstream>[^ ]*)/
  time_format %d/%b/%Y:%H:%M:%S %z
</source>


# idr-analysis.openmicroscopy.org Haproxy
# Log format: httplog with syslog prefix
# https://github.com/IDR/deployment/blob/92b015dac3740f1256261f4b34e267b7d97a25b6/ansible/templates/k8sproxy-haproxy.cfg.j2#L16
# https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#8.2.3
# Examples:
# Feb  1 22:40:56 localhost haproxy[20511]: 192.0.2.0:25308 [01/Feb/2019:22:40:55.919] web-http~ web-vae-http/vae-192_168_8_29 98/0/0/5/103 302 469 - - ---- 7/7/0/1/0 0/0 "GET /public/user/179a5c4f-40ef-499f-bf62-c270b0ea3444/ HTTP/1.1"
# Feb  1 22:41:00 localhost haproxy[20511]: 192.0.2.0:25308 [01/Feb/2019:22:40:59.952] web-http~ web-vae-http/vae-192_168_8_29 67/0/0/8/75 302 1325 - - ---- 7/7/0/1/0 0/0 "GET /public/user/179a5c4f-40ef-499f-bf62-c270b0ea3444/lab?redirects=1 HTTP/1.1"
# Dec 31 07:09:52 localhost haproxy[20511]: 71.6.199.23:56568 [31/Dec/2018:07:09:51.877] web-http~ web-http/<NOSRV> -1/-1/-1/-1/283 400 187 - - CR-- 0/0/0/0/0 0/0 "<BADREQ>"
<source>
  @type tail
  path /idranalysis-haproxy-logs/haproxy-http.log-*
  pos_file /fluentd/pos/idranalysis-haproxy-logs-http.pos
  read_from_head true
  tag haproxy.http

  # Based on https://gist.github.com/tomplayford/509a1444e7a0e81dd2ab
  format /^(?<syslog_header>[^ ]* +[^ ]* +[^ ]* [^ ]* (\w+)\[(\d+)\]): (?<host>[\w\.]+):(?<c_port>\d+) \[(?<time>.+)\] (?<f_end>[^ ]+) (?<b_end>[^\/]+)\/(?<b_server>[^ ]+) (?<tq>-?\d+)\/(?<tw>-?\d+)\/(?<tc>-?\d+)\/(?<tr>-?\d+)\/(?<tt>[-+]?\d+) (?<code>\d+) (?<size>\d+) (?<req_cookie>\S?) (?<res_cookie>\S?) (?<t_state>[\w-]+) (?<actconn>\d+)\/(?<feconn>\d+)\/(?<beconn>\d+)\/(?<srv_conn>\d+)\/(?<retries>\d+) (?<srv_queue>\d+)\/(?<backend_queue>\d+) \{?(?<req_headers>[^}]*)\}? ?\{?(?<res_headers>[^}]*)\}? ?"(?<request>((?<method>\S+) (?<path1>/[^ \/\?]*)(?<path2>/[^ \/\?]*)?(?<path3>/[^ \/\?]*)?(?<path4>/[^ \/\?]*)?(?<path_n>/[^ \?]*)?(?<query>\?[^ ]*)?( (?<http_ver>\S+))?)|([^\"]*))"/
  time_format %d/%b/%Y:%H:%M:%S.%L
</source>


# Ignore internal
<filter nginx.access haproxy.http>
  @type grep
  <exclude>
    key host
    # TODO: 172.17-32
    pattern ^(127\.|192\.168\.)
  </exclude>
</filter>

# Ignore prometheus federation
<filter haproxy.http>
  @type grep
  <and>
    <exclude>
      key path1
      pattern /\/prometheus/
    </exclude>
    <exclude>
      key path2
      pattern /\/federate/
    </exclude>
  </and>
</filter>

# Geo-locate IP
<filter nginx.access haproxy.http>
  @type geoip
  geoip_lookup_keys host
  backend_library geoip2_c
  <record>
    city            ${city.names.en["host"]}
    region_name     ${subdivisions.0.names.en["host"]}
    country_name    ${country.names.en["host"]}
    country         ${country.iso_code["host"]}
    region_code     ${subdivisions.0.iso_code["host"]}
    #latitude        ${latitude["host"]}
    #longitude       ${longitude["host"]}
    # https://github.com/y-ken/fluent-plugin-geoip/issues/16#issuecomment-167689994
    #geoip           '{"location":[${location.longitude["host"]},${location.latitude["host"]}],"country":${country_code["host"]}}'
    #geoip '{"location":[${longitude["host"]},${latitude["host"]}]}'
    # https://github.com/y-ken/fluent-plugin-geoip#advanced-config-samples
    geoip '{ "lat" : ${location.latitude["host"]}, "lon" : ${location.longitude["host"]} }'
  </record>
  # To avoid get stacktrace error with `[null, null]` array for elasticsearch.
  skip_adding_null_record  true
</filter>

# Uncomment for debugging
#<filter **>
#  @type stdout
#</filter>

# Ensure each ES record has a unique ID:
# https://github.com/uken/fluent-plugin-elasticsearch/tree/v3.2.0#generate-hash-id
<filter nginx.* haproxy.*>
  @type elasticsearch_genid
  hash_id_key _hash
</filter>

#<match nginx.* haproxy.*>
#  @type relabel
#  @label @ELASTICSEARCH
#</match>

<match nginx.*>
  @type copy
  <store>
    @type relabel
    @label @ELASTICSEARCH
  </store>
  <store>
    @type flowcounter
    @label @STDOUT
    count_keys *
    unit minute
    timestamp_counting true
    aggregate all
    tag flow.nginx
  </store>
</match>

<match haproxy.*>
  @type copy
  <store>
    @type relabel
    @label @ELASTICSEARCH
  </store>
  <store>
    @type flowcounter
    @label @STDOUT
    count_keys *
    unit minute
    timestamp_counting true
    aggregate all
    tag flow.haproxy
  </store>
</match>

<label @STDOUT>
  <match **>
    @type stdout
  </match>
</label>

<label @ELASTICSEARCH>
  <match **>
    @type elasticsearch
    host elasticsearch
    port 9200

    id_key _hash
    remove_keys _hash
    include_tag_key true
    tag_key @log_name

    #include_timestamp true
    #index_name fluentd.${tag}.%Y%m%d
    logstash_format true
    logstash_prefix fluentd.${tag}

    templates { "idr-web": "/fluentd/etc/elasticsearch-template.json"}
    template_overwrite true
    type_name fluentd
    #<buffer tag, time>
    <buffer tag>
      flush_interval 10s
      #chunk_limit_size 8MB
      #timekey 10s
      #timekey_wait 10s
      #overflow_action block
      flush_at_shutdown true
      #flush_mode interval
      flush_thread_count 2
    </buffer>

    #@log_level debug
    log_es_400_reason true
    request_timeout 60s
  </match>
</label>
